{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfdbfb8e-b47f-4dd8-a083-d3a770ade74f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**SIMPLE ETL TEMPLATE - MULTI-DATA SOURCE JSON VIA S3 + CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d749f6f-ab17-413a-8e8f-ef4ca89cf4c8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "EMPTY PATIENT BRONZE TABLE"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "---Create PATIENT_BRONZE Delta Table using SQL\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS patient_bronze (\n",
    "    patient_id           STRING,\n",
    "    member_email         STRING,\n",
    "    first_name           STRING,\n",
    "    last_name            STRING,\n",
    "    date_of_birth        STRING,\n",
    "    gender               STRING,\n",
    "    address              STRING,\n",
    "    city                 STRING,\n",
    "    state                STRING,\n",
    "    zip_code             STRING,\n",
    "    phone_number         STRING,\n",
    "    creation_date        STRING,  \n",
    "    last_visit_date      STRING,  \n",
    "    last_known_ip        STRING   \n",
    ")\n",
    "USING DELTA\n",
    "LOCATION '/mnt/datalake/patient_bronze/'\n",
    "TBLPROPERTIES (\n",
    "    'delta.enableChangeDataFeed' = 'true'\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63e5ced7-bb08-4041-8955-4b74aafa496a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load JSON data from S3 to Bronze Table using Autoloader"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "bronze_schema = \n",
    "    patient_id           STRING,\n",
    "    member_email         STRING,\n",
    "    first_name           STRING,\n",
    "    last_name            STRING,\n",
    "    date_of_birth        STRING,\n",
    "    gender               STRING,\n",
    "    address              STRING,\n",
    "    city                 STRING,\n",
    "    state                STRING,\n",
    "    zip_code             STRING,\n",
    "    phone_number         STRING,\n",
    "    creation_date        STRING, \n",
    "    last_visit_date      STRING,  \n",
    "    last_known_ip        STRING \n",
    "\n",
    "raw_path = \"s3a://your-generic-bucket/raw/patient_json/\"\n",
    "\n",
    "bronze_df = (\n",
    "    spark.readStream\n",
    "    .format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"json\")\n",
    "    .schema(bronze_schema)\n",
    "    .load(raw_path)\n",
    ")\n",
    "\n",
    "bronze_df.writeStream \\\n",
    "    .format(\"delta\") \\\n",
    "    .option(\"checkpointLocation\", \"/mnt/datalake/_checkpoints/patient_bronze/\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start(\"/mnt/datalake/patient_bronze/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a739c617-b36e-4627-97b4-cb21c74cf656",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Query PATIENT_BRONZE table"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM patient_bronze LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "827ac65d-79db-4a39-b41c-459628745f74",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TRANSFORMATION"
    }
   },
   "outputs": [],
   "source": [
    "# Clean and Anonymize to patient_Silver Table\n",
    "\n",
    "from pyspark.sql.functions import sha2, concat_ws, to_date\n",
    "\n",
    "patient_bronze_df = spark.read.format(\"delta\").load(\"/mnt/datalake/patient_bronze/\")\n",
    "\n",
    "patient_silver_df = patient_bronze_df \\\n",
    "    .withColumn(\"email\", sha2(col(\"email\"), 256)) \\ \n",
    "    .withColumn(\"creation_date\", to_date(\"creation_date\", \"yyyy-MM-dd\")) \\\n",
    "    .withColumn(\"last_activity_date\", to_date(\"last_activity_date\", \"yyyy-MM-dd\"))\n",
    "\n",
    "patient_silver_df.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/datalake/patient_silver/\")\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS patient_silver USING DELTA LOCATION '/mnt/datalake/patient_silver/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af2f7237-b9dd-42fb-b774-c246b8974da5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TESTING/DATA VALIDATION (JSONSILVER)"
    }
   },
   "outputs": [],
   "source": [
    "# Null check\n",
    "assert patient_silver_df.filter(\"email IS NULL\").count() == 0, \"Missing emails found\"\n",
    "\n",
    "# Date format check\n",
    "invalid_dates = patient_silver_df.filter(col(\"creation_date\").isNull() | col(\"last_activity_date\").isNull())\n",
    "assert invalid_dates.count() == 0, \"Date conversion issues found\"\n",
    "\n",
    "# Duplicate email check\n",
    "email_count = patient_silver_df.count()\n",
    "distinct_email_count = patient_silver_df.select(\"email\").distinct().count()\n",
    "assert email_count == distinct_email_count, \"Duplicate emails found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11419f86-080b-4432-ae86-45b54d1b0530",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "INGEST Additional (CLAIMS)CSV data"
    }
   },
   "outputs": [],
   "source": [
    "# Ingest customer claims data (CSV to claims_silver)\n",
    "\n",
    "claims_schema = [\n",
    "    (\"claim_id\", \"STRING\"),\n",
    "    (\"member_id\", \"STRING\"),\n",
    "    (\"member_email\", \"STRING\"),\n",
    "    (\"claim_type\", \"STRING\"),  # e.g., inpatient, outpatient, pharmacy\n",
    "    (\"provider_id\", \"STRING\"),\n",
    "    (\"provider_name\", \"STRING\"),\n",
    "    (\"service_start_date\", \"STRING\"),\n",
    "    (\"service_end_date\", \"STRING\"),\n",
    "    (\"claim_submission_date\", \"STRING\"),\n",
    "    (\"claim_status\", \"STRING\"),  # e.g., approved, denied, pending\n",
    "    (\"diagnosis_code\", \"STRING\"),  # ICD-10 codes\n",
    "    (\"procedure_code\", \"STRING\"),  # CPT/HCPCS codes\n",
    "    (\"billed_amount\", \"FLOAT\"),\n",
    "    (\"allowed_amount\", \"FLOAT\"),\n",
    "    (\"paid_amount\", \"FLOAT\"),\n",
    "    (\"patient_responsibility\", \"FLOAT\"),\n",
    "    (\"last_processed_date\", \"STRING\"),\n",
    "    (\"payer_name\", \"STRING\")\n",
    "]\n",
    "csv_path = \"/mnt/datalake/raw/patient_claims_csv/\"\n",
    "\n",
    "claims_df = (\n",
    "    spark.readStream\n",
    "    .format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .schema(claims_schema)\n",
    "    .load(csv_path)\n",
    ")\n",
    "\n",
    "claims_df.writeStream \\\n",
    "    .format(\"delta\") \\\n",
    "    .option(\"checkpointLocation\", \"/mnt/datalake/_checkpoints/claims_silver/\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start(\"/mnt/datalake/claims_silver/\")\n",
    "\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS claims_silver USING DELTA LOCATION '/mnt/datalake/claims_silver/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47da1fe6-a0e0-407d-baf7-63dbe668e787",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TESTING/VALIDATION (CSVSILVER)"
    }
   },
   "outputs": [],
   "source": [
    "assert claims_df.columns is not None, \"Claims CSV missing columns\"\n",
    "assert claims_df.count() > 0, \"Claims data is empty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e2aca9a-73df-41c3-8132-fd74ee131f16",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "GOLD TABLE"
    }
   },
   "outputs": [],
   "source": [
    "# Join patient_silver and claims_silver into patient_claims_gold\n",
    "\n",
    "patient_silver_df = spark.read.format(\"delta\").load(\"/mnt/datalake/patient_silver/\")\n",
    "claims_silver_df = spark.read.format(\"delta\").load(\"/mnt/datalake/claims_silver/\")\n",
    "\n",
    "patient_claims_gold_df = patient_silver_df.join(claims_silver_df, on=\"email\", how=\"inner\")\n",
    "\n",
    "patient_claims_gold_df.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/datalake/patient_gold/\")\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS patient_gold USING DELTA LOCATION '/mnt/datalake/patient_gold/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57300bae-61d4-4e7d-b075-09ab1f1bfa4a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "DML Operations (DELETE/UPDATE/MERGE"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "---perform any additinoal DML operations for further transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05559381-6ec8-4ec3-b4a1-167ea07efd66",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "FINAL TESTING/VALIDATION (GOLD)"
    }
   },
   "outputs": [],
   "source": [
    "# Join integrity check\n",
    "assert patient_claims_gold_df.count() > 0, \"Gold table has no data after join\"\n",
    "\n",
    "# Optional: sample metric check\n",
    "if \"total_claims\" in patient_claims_gold_df.columns:\n",
    "    assert patient_claims_gold_df.filter(col(\"total_claims\") < 0).count() == 0, \"Invalid claims values detected\"\n",
    "\n",
    "print(\"All validations passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "170b28ec-f6e1-48e1-830d-2e8d7043f98a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "FINAL TABLES"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "---Final tables ready to be used to be for consumption (Dashboards, ML models, Analytics, etc) "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Simple ETL Template",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}